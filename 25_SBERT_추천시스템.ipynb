{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOueuG72VT4TczYTdzZIfKi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXp2PdVSS2Zq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install sentence_transformers\n",
        "\n",
        "# 추천 시스템 - SBERT\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import linear_kernel                             # 다수 문장에 대한 유사도 계산\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# 테스트 데이터\n",
        "file_path = '/content/drive/MyDrive/NLP/movies_metadata.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터 전처리\n",
        "null_overview = df.overview.isnull().sum()                                     # 결측치 확인\n",
        "null_title = df.title.isnull().sum()\n",
        "\n",
        "df.dropna(subset = ['overview', 'title'], inplace = True)                      # 결측치 제거\n",
        "df.reset_index(drop = True, inplace=True)                                      # 인덱스 재설정\n",
        "data = df.iloc[:10000, :]                                                      # 일부 데이터 활용\n",
        "\n",
        "np_embeddings = np.array([data.overview.apply(lambda x: model.encode(x))])     # 임베딩 벡터 생성\n",
        "\n",
        "embedding_path = '/content/drive/MyDrive/NLP/overview_embeddings.npy'          # 임베딩 벡터 저장\n",
        "np.save(embedding_path, np_embeddings)\n",
        "\n",
        "# 저장된 임베딩 벡터 불러오기\n",
        "embedding_path = '/content/drive/MyDrive/NLP/overview_embeddings.npy'\n",
        "embedding_vectors = np.load(embedding_path, allow_pickle = True)\n",
        "\n",
        "data['embedding'] = embedding_vectors[0]                                       # embedding이라는 새로운 컬럼을 생성\n",
        "\n",
        "embedding_vectors = data.embedding.values                                      # 문장 임베딩 벡터 추출\n",
        "\n",
        "embedding_matrix = []                                                          # 문장 행렬 생성\n",
        "for vector in embedding_vectors:\n",
        "    embedding_matrix.append(vector)\n",
        "print(np.array(embedding_matrix).shape)\n",
        "\n",
        "similarity = linear_kernel(embedding_matrix, embedding_matrix)                 # overview에 대한 유사도 구하기\n",
        "title_index = pd.Series(data= data.index, index = data.title)                  # 인덱스와 제목 위치 교환\n",
        "\n",
        "# 영화 추천함수\n",
        "def recommend(title, similarity):\n",
        "    idx = title_index[title]                                                   # 선택한 영화의 제목에서 유사한 영화의 인덱스 구하기\n",
        "    sim_score = [(idx, score) for idx, score in enumerate(similarity[idx])]    # 모든 영화에 대해 해당 영화와의 유사도를 구함\n",
        "    sim_score = sorted(sim_score, key=lambda x: -x[1])                         # 유사도에 따른 영화 정렬\n",
        "\n",
        "    movie_index = []                                                           # 유사도가 가장 큰 영화 인덱스 추출\n",
        "    for data in sim_score:\n",
        "        movie_index.append(data[0])\n",
        "    movie_title = df.title[movie_index]                                        # 유사도가 가장 큰 10개 추천의 제목\n",
        "\n",
        "    return movie_title\n",
        "\n",
        "recommend_movie = recommend('Jumanji', similarity)[:10]\n",
        "print(recommend_movie)"
      ]
    }
  ]
}